"use strict";(globalThis.webpackChunkpy_omni_ts_docs=globalThis.webpackChunkpy_omni_ts_docs||[]).push([[356],{8117(e,n,s){s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"tutorial/get_started","title":"\ud83d\ude80 Get Started","description":"This tutorial guides you running experiments.","source":"@site/docs/tutorial/1_get_started.md","sourceDirName":"tutorial","slug":"/tutorial/get_started","permalink":"/PyOmniTS-docs/docs/tutorial/get_started","draft":false,"unlisted":false,"editUrl":"https://github.com/Ladbaby/PyOmniTS-docs/tree/main/docs/tutorial/1_get_started.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Tutorial","permalink":"/PyOmniTS-docs/docs/category/tutorial"},"next":{"title":"\u2699\ufe0f Change Experiment Settings","permalink":"/PyOmniTS-docs/docs/tutorial/change_experiment_settings"}}');var t=s(4848),r=s(8453);const a={sidebar_position:1},l="\ud83d\ude80 Get Started",o={},c=[{value:"1. \u23ec Clone the Repository",id:"1--clone-the-repository",level:2},{value:"2. \ud83d\udcbf Prepare the Environment",id:"2--prepare-the-environment",level:2},{value:"3. \ud83d\udcbe Prepare Datasets",id:"3--prepare-datasets",level:2},{value:"3.1 Regular",id:"31-regular",level:3},{value:"3.2 Irregular",id:"32-irregular",level:3},{value:"3.2.1 Human Activity",id:"321-human-activity",level:4},{value:"3.2.2 MIMIC III",id:"322-mimic-iii",level:4},{value:"3.2.2 MIMIC IV",id:"322-mimic-iv",level:4},{value:"3.2.3 PhysioNet&#39;12",id:"323-physionet12",level:4},{value:"3.2.4 USHCN",id:"324-ushcn",level:4},{value:"4. \ud83d\udcc2 (Optional) Folder Structure",id:"4--optional-folder-structure",level:2},{value:"5. \ud83d\udd25 Training",id:"5--training",level:2},{value:"6. \u2744\ufe0f Testing",id:"6-\ufe0f-testing",level:2}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"-get-started",children:"\ud83d\ude80 Get Started"})}),"\n",(0,t.jsx)(n.p,{children:"This tutorial guides you running experiments."}),"\n",(0,t.jsx)(n.h2,{id:"1--clone-the-repository",children:"1. \u23ec Clone the Repository"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"cd /path/to/your/project\ngit clone https://github.com/Ladbaby/PyOmniTS.git\n"})}),"\n",(0,t.jsx)(n.h2,{id:"2--prepare-the-environment",children:"2. \ud83d\udcbf Prepare the Environment"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Create a new Python virtual environment via the tool of your choice, and activate it. For example, using ",(0,t.jsx)(n.a,{href:"https://docs.conda.io/en/latest/miniconda.html",children:"Miniconda"}),"/",(0,t.jsx)(n.a,{href:"https://www.anaconda.com/",children:"Anaconda"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"conda create -n pyomnits python=3.12\nconda activate pyomnits\n"})}),"\n",(0,t.jsx)(n.p,{children:"Python 3.10~3.12 have been tested."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Install dependencies."}),"\n",(0,t.jsx)(n.p,{children:"Choose one of the options:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Option 1: Fuzzy package versions, the legacy way."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"pip install -r requirements.txt\n"})}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:["\ud83d\udca1 For faster installation speed, consider installing ",(0,t.jsx)(n.a,{href:"https://github.com/astral-sh/uv",children:"uv"})," and running ",(0,t.jsx)(n.code,{children:"uv pip install -r requirements.txt"})," instead."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Option 2: Exact package versions, the aggressive way."}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsx)(n.p,{children:"\u26a0\ufe0f It assumes your Linux server to have cuda version 12, which can be less flexible than option 1."}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Install ",(0,t.jsx)(n.a,{href:"https://github.com/astral-sh/uv",children:"uv"}),", then:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"uv pip sync requirements.lock\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:["\ud83d\udd25Note: some packages are only used by a few models/datasets, which are optional. See comments in ",(0,t.jsx)(n.code,{children:"requirements.txt"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"3--prepare-datasets",children:"3. \ud83d\udcbe Prepare Datasets"}),"\n",(0,t.jsx)(n.h3,{id:"31-regular",children:"3.1 Regular"}),"\n",(0,t.jsxs)(n.p,{children:["Get them from ",(0,t.jsx)(n.a,{href:"https://drive.google.com/drive/folders/13Cg1KYOlzM5C7K8gK8NfC-F3EYxkM3D2",children:"[Google Drive]"})," provided by ",(0,t.jsx)(n.a,{href:"https://github.com/thuml/Time-Series-Library",children:"Time-Series-Library"}),", which includes the following datasets in this repository:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"ECL (electricity)"}),"\n",(0,t.jsx)(n.li,{children:"ETTh1 (ETT-small)"}),"\n",(0,t.jsx)(n.li,{children:"ETTm1 (ETT-small)"}),"\n",(0,t.jsx)(n.li,{children:"ILI (illness)"}),"\n",(0,t.jsx)(n.li,{children:"Traffic (traffic)"}),"\n",(0,t.jsx)(n.li,{children:"Weather (weather)"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["And place them under ",(0,t.jsx)(n.code,{children:"storage/datasets"})," folder of this project (create the folder if not exists, or you can use symbolic link ",(0,t.jsx)(n.code,{children:"ln -s"})," to redirect to existing dataset files)."]}),"\n",(0,t.jsxs)(n.p,{children:["You will get the following file structure under ",(0,t.jsx)(n.code,{children:"storage/datasets"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:".\n\u251c\u2500\u2500 electricity/\n\u2502   \u2514\u2500\u2500 electricity.csv\n\u251c\u2500\u2500 ETT-small/\n\u2502   \u251c\u2500\u2500 ETTh1.csv\n\u2502   \u251c\u2500\u2500 ETTh2.csv\n\u2502   \u251c\u2500\u2500 ETTm1.csv\n\u2502   \u2514\u2500\u2500 ETTm2.csv\n\u251c\u2500\u2500 illness/\n\u2502   \u2514\u2500\u2500 national_illness.csv\n\u251c\u2500\u2500 traffic/\n\u2502   \u2514\u2500\u2500 traffic.csv\n\u2514\u2500\u2500 weather/\n    \u2514\u2500\u2500 weather.csv\n"})}),"\n",(0,t.jsx)(n.h3,{id:"32-irregular",children:"3.2 Irregular"}),"\n",(0,t.jsx)(n.h4,{id:"321-human-activity",children:"3.2.1 Human Activity"}),"\n",(0,t.jsx)(n.p,{children:"No need to prepare in advance.\nOur code will automatically download then preprocess it if you want to train on it."}),"\n",(0,t.jsxs)(n.p,{children:["The following file structure will be found under ",(0,t.jsx)(n.code,{children:"storage/datasets"}),", after the code finish preprocessing:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:".\n\u2514\u2500\u2500 HumanActivity/\n    \u251c\u2500\u2500 processed/\n    \u2502   \u2514\u2500\u2500 data.pt\n    \u2514\u2500\u2500 raw/\n        \u2514\u2500\u2500 ConfLongDemo_JSI.txt\n"})}),"\n",(0,t.jsx)(n.h4,{id:"322-mimic-iii",children:"3.2.2 MIMIC III"}),"\n",(0,t.jsx)(n.p,{children:"Since MIMIC III requires credentialed access:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Request for raw data from ",(0,t.jsx)(n.a,{href:"https://physionet.org/content/mimiciii/1.4/",children:"here"}),". Files can be put wherever you like, and you don't have to extract ",(0,t.jsx)(n.code,{children:".csv.gz"})," as ",(0,t.jsx)(n.code,{children:".csv"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Data preprocessing"}),"\n",(0,t.jsx)(n.p,{children:"Choose one of the options:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Option 1: Use the revised scripts in PyOmniTS.","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Create a new virtual environment (only used in data preprocessing, not subsequent training) with Python 3.7, numpy 1.21.6, and pandas 1.3.5"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"conda create -n python37 python=3.7\nconda activate python37\npip install numpy==1.21.6 pandas==1.3.5\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"python data/dependencies/MIMIC_III/preprocess/0_run_all.py"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Option 2: Use the original scripts in gru_ode_bayes.","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Follow the processing scripts in ",(0,t.jsx)(n.a,{href:"https://github.com/edebrouwer/gru_ode_bayes/tree/master/data_preproc/MIMIC",children:"gru_ode_bayes"})," to get ",(0,t.jsx)(n.code,{children:"complete_tensor.csv"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Put the result under ",(0,t.jsx)(n.code,{children:"~/.tsdm/rawdata/MIMIC_III_DeBrouwer2019/complete_tensor.csv"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["The following file structure will be found under ",(0,t.jsx)(n.code,{children:"~/.tsdm"}),", after the code finish preprocessing (Note: ",(0,t.jsx)(n.code,{children:".parquet"})," files will be generated automatically after training any model on this dataset):"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:".\n\u251c\u2500\u2500 datasets/\n\u2502   \u2514\u2500\u2500 MIMIC_III_DeBrouwer2019/\n\u2502       \u251c\u2500\u2500 metadata.parquet\n\u2502       \u2514\u2500\u2500 timeseries.parquet\n\u2514\u2500\u2500 rawdata/\n    \u2514\u2500\u2500 MIMIC_III_DeBrouwer2019/\n        \u2514\u2500\u2500 complete_tensor.csv\n"})}),"\n",(0,t.jsx)(n.h4,{id:"322-mimic-iv",children:"3.2.2 MIMIC IV"}),"\n",(0,t.jsx)(n.p,{children:"Since MIMIC IV requires credentialed access:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Request for raw data from ",(0,t.jsx)(n.a,{href:"https://physionet.org/content/mimiciv/1.0/",children:"here"}),". Files can be put wherever you like, and you don't have to extract ",(0,t.jsx)(n.code,{children:".csv.gz"})," as ",(0,t.jsx)(n.code,{children:".csv"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Data preprocessing"}),"\n",(0,t.jsx)(n.p,{children:"Choose one of the options:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Option 1: Use the revised scripts in PyOmniTS.","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Create a new virtual environment (only used in data preprocessing, not subsequent training) with Python 3.8, numpy 1.24.4, and pandas 2.0.3"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"conda create -n python38 python=3.8\nconda activate python38\npip install numpy==1.24.4 pandas==2.0.3\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"python data/dependencies/MIMIC_IV/preprocess/0_run_all.py"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Option 2: Use the original scripts in NeuralFlows.","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Follow the processing scripts in ",(0,t.jsx)(n.a,{href:"https://github.com/mbilos/neural-flows-experiments/blob/master/nfe/experiments/gru_ode_bayes/data_preproc",children:"NeuralFlows"})," to get ",(0,t.jsx)(n.code,{children:"full_dataset.csv"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Put the result under ",(0,t.jsx)(n.code,{children:"~/.tsdm/rawdata/MIMIC_IV_Bilos2021/full_dataset.csv"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["The following file structure will be found under ",(0,t.jsx)(n.code,{children:"~/.tsdm"}),", after the code finish preprocessing (Note: ",(0,t.jsx)(n.code,{children:".parquet"})," files will be generated automatically after training any model on this dataset):"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:".\n\u251c\u2500\u2500 datasets/\n\u2502   \u2514\u2500\u2500 MIMIC_IV_Bilos2021/\n\u2502       \u2514\u2500\u2500 timeseries.parquet\n\u2514\u2500\u2500 rawdata/\n    \u2514\u2500\u2500 MIMIC_IV_Bilos2021/\n        \u2514\u2500\u2500 full_dataset.csv\n"})}),"\n",(0,t.jsx)(n.h4,{id:"323-physionet12",children:"3.2.3 PhysioNet'12"}),"\n",(0,t.jsx)(n.p,{children:"No need to prepare in advance.\nOur code will automatically download then preprocess it if you want to train on it."}),"\n",(0,t.jsxs)(n.p,{children:["The following file structure will be found under ",(0,t.jsx)(n.code,{children:"~/.tsdm"}),", after the code finish preprocessing:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:".\n\u251c\u2500\u2500 datasets/\n\u2502   \u2514\u2500\u2500 Physionet2012/\n\u2502       \u251c\u2500\u2500 Physionet2012-set-A-sparse.tar\n\u2502       \u251c\u2500\u2500 Physionet2012-set-B-sparse.tar\n\u2502       \u2514\u2500\u2500 Physionet2012-set-C-sparse.tar\n\u2514\u2500\u2500 rawdata/\n    \u2514\u2500\u2500 Physionet2012/\n        \u251c\u2500\u2500 set-a.tar.gz\n        \u251c\u2500\u2500 set-b.tar.gz\n        \u2514\u2500\u2500 set-c.tar.gz\n"})}),"\n",(0,t.jsx)(n.h4,{id:"324-ushcn",children:"3.2.4 USHCN"}),"\n",(0,t.jsx)(n.p,{children:"No need to prepare in advance.\nOur code will automatically download then preprocess it if you want to train on it."}),"\n",(0,t.jsxs)(n.p,{children:["The following file structure will be found under ",(0,t.jsx)(n.code,{children:"~/.tsdm"}),", after the code finish preprocessing:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:".\n\u251c\u2500\u2500 datasets/\n\u2502   \u2514\u2500\u2500 USHCN_DeBrouwer2019/\n\u2502       \u2514\u2500\u2500 USHCN_DeBrouwer2019.parquet\n\u2514\u2500\u2500 rawdata/\n    \u2514\u2500\u2500 USHCN_DeBrouwer2019/\n        \u2514\u2500\u2500 small_chunked_sporadic.csv\n"})}),"\n",(0,t.jsx)(n.h2,{id:"4--optional-folder-structure",children:"4. \ud83d\udcc2 (Optional) Folder Structure"}),"\n",(0,t.jsx)(n.p,{children:"You can optionally learn how PyOmniTS organize its folder structure:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:".\n\u251c\u2500\u2500 configs/ # (Auto-generated) YAML configs for experiments. Only saved as references, not input parameters.\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 data_provider/\n|   |   \u251c\u2500\u2500 datasets/ # Main classes of datasets. File names match the string provided in --dataset_name.\n|   |   \u2514\u2500\u2500 data_factory.py # Provides an interface to get torch.utils.data.Dataset and torch.utils.data.DataLoader\n|   \u2514\u2500\u2500 dependencies/ # Dependencies for dataset classes under data/data_provider/datasets/\n\u251c\u2500\u2500 docs # Documentations\n\u251c\u2500\u2500 exp/\n|   \u251c\u2500\u2500 exp_basic.py # Parent class for experiments.\n|   \u2514\u2500\u2500 exp_main.py # Main class for experiments, inherit from the class in exp_basic.py\n\u251c\u2500\u2500 layers/ # Dependencies for model classes under models/\n\u251c\u2500\u2500 logs/ # (Auto-generated) Auto-rotated logs when running experiments.\n\u251c\u2500\u2500 loss_fns/ # Main classes of loss functions. File names match the string provided in --loss.\n\u251c\u2500\u2500 lr_schedulers/ # Main classes of some learning rate schedulers.\n\u251c\u2500\u2500 models/ # Main classes of models. File names match the string provided in --model_name.\n\u251c\u2500\u2500 scripts/ # Launch scripts for experiments.\n\u251c\u2500\u2500 storage/ # (Auto-generated) General purpose storage folder, not recorded by git.\n|   \u251c\u2500\u2500 datasets/ # Time series data for some datasets.\n|   \u2514\u2500\u2500 results/ # Experiment results.\n\u251c\u2500\u2500 tests/ # Unit tests only used by PyOmniTS maintainers.\n\u251c\u2500\u2500 utils/\n|   \u251c\u2500\u2500 configs.py # Command line arguments accepted by main.py\n|   \u251c\u2500\u2500 ExpConfigs.py # Dataclass that wraps utils/configs.py for typo check. Passed to models, datasets, loss_fns,... for their initializations.\n|   \u251c\u2500\u2500 globals.py # A few global variables (logger, accelerator,...).\n|   \u251c\u2500\u2500 metrics.py # Calculate metrics (e.g., MSE) during testing.\n|   \u2514\u2500\u2500 tools.py # misc helper functions and classes.\n\u251c\u2500\u2500 wandb/ # (Auto-generated) Weight & Bias logs when --wandb 1 or --sweep 1.\n\u251c\u2500\u2500 .all-contributorsrc # Only used in README.md.\n\u251c\u2500\u2500 .gitignore # Git ignore rules.\n\u251c\u2500\u2500 .python-version # Recommended Python version, display only.\n\u251c\u2500\u2500 LICENSE # MIT License.\n\u251c\u2500\u2500 main.py # Main entrance for experiments.\n\u251c\u2500\u2500 pyproject.toml # Standard configuration file for Python projects.\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 requirements.lock # Python package requirements (with versions).\n\u251c\u2500\u2500 requirements.txt # Python package requirements (without versions).\n\u251c\u2500\u2500 run_unittest.sh # Launch script for unit tests in tests/. Only used by PyOmniTS maintainers.\n\u2514\u2500\u2500 run.sh # Launch script for scripts/. Useful when launching multiple experiments at once.\n"})}),"\n",(0,t.jsx)(n.p,{children:"Core logic when running experiments:"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"scripts/"})," \u2192 ",(0,t.jsx)(n.code,{children:"main.py"})," \u2192 ",(0,t.jsx)(n.code,{children:"exp/exp_main.py"})]}),"\n",(0,t.jsx)(n.h2,{id:"5--training",children:"5. \ud83d\udd25 Training"}),"\n",(0,t.jsxs)(n.p,{children:["Training scripts are located in ",(0,t.jsx)(n.code,{children:"scripts"})," folder.\nFor example, to train mTAN on dataset Human Activity:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"sh scripts/mTAN/HumanActivity.sh\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Training results will be organized in ",(0,t.jsx)(n.code,{children:"storage/results/${DATASET_NAME}/${DATASET_ID}/${MODEL_NAME}/${MODEL_ID}/${SEQ_LEN}_${PRED_LEN}/%Y_%m%d_%H%M/iter0"})]}),"\n",(0,t.jsx)(n.h2,{id:"6-\ufe0f-testing",children:"6. \u2744\ufe0f Testing"}),"\n",(0,t.jsxs)(n.p,{children:["Testing will be automatically conducted once the training finished.\nIf you wish to run test only, change command line argument ",(0,t.jsx)(n.code,{children:"--is_training"})," in training script from ",(0,t.jsx)(n.code,{children:"1"})," to ",(0,t.jsx)(n.code,{children:"0"})," and run the script."]}),"\n",(0,t.jsxs)(n.p,{children:["Testing result ",(0,t.jsx)(n.code,{children:"metric.json"})," will be saved in ",(0,t.jsx)(n.code,{children:"storage/results/${DATASET_NAME}/${DATASET_ID}/${MODEL_NAME}/${MODEL_ID}/${SEQ_LEN}_${PRED_LEN}/%Y_%m%d_%H%M/iter0/eval_%Y_%m%d_%H%M"})]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453(e,n,s){s.d(n,{R:()=>a,x:()=>l});var i=s(6540);const t={},r=i.createContext(t);function a(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);