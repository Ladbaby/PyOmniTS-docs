"use strict";(globalThis.webpackChunkpy_omni_ts_docs=globalThis.webpackChunkpy_omni_ts_docs||[]).push([[81],{3420(e,n,t){t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>r,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"tutorial/change_experiment_settings","title":"\u2699\ufe0f Change Experiment Settings","description":"This tutorial guides you changing the settings of your experiments.","source":"@site/docs/tutorial/2_change_experiment_settings.md","sourceDirName":"tutorial","slug":"/tutorial/change_experiment_settings","permalink":"/PyOmniTS-docs/docs/tutorial/change_experiment_settings","draft":false,"unlisted":false,"editUrl":"https://github.com/Ladbaby/PyOmniTS-docs/tree/main/docs/tutorial/2_change_experiment_settings.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"\ud83d\ude80 Get Started","permalink":"/PyOmniTS-docs/docs/tutorial/get_started"},"next":{"title":"Forecasting","permalink":"/PyOmniTS-docs/docs/category/forecasting"}}');var s=t(4848),a=t(8453);const l={sidebar_position:2},r="\u2699\ufe0f Change Experiment Settings",o={},d=[{value:"1. Overview",id:"1-overview",level:2},{value:"2. Change Settings",id:"2-change-settings",level:2},{value:"3. Commonly Used Settings",id:"3-commonly-used-settings",level:2},{value:"4. Other Settings",id:"4-other-settings",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"\ufe0f-change-experiment-settings",children:"\u2699\ufe0f Change Experiment Settings"})}),"\n",(0,s.jsx)(n.p,{children:"This tutorial guides you changing the settings of your experiments."}),"\n",(0,s.jsx)(n.h2,{id:"1-overview",children:"1. Overview"}),"\n",(0,s.jsxs)(n.p,{children:["All available setting options are defined in ",(0,s.jsx)(n.code,{children:"utils/configs.py"}),", where PyOmniTS uses Python's built-in ",(0,s.jsx)(n.code,{children:"argparse"})," package to configure all the settings."]}),"\n",(0,s.jsx)(n.h2,{id:"2-change-settings",children:"2. Change Settings"}),"\n",(0,s.jsxs)(n.p,{children:["It is recommended to overwrite the values of these settings via the scripts under the ",(0,s.jsx)(n.code,{children:"scripts/"})," folder.\nChanging default values of arguments in ",(0,s.jsx)(n.code,{children:"utils/configs.py"})," is not recommended, which may affect other PyOmniTS components."]}),"\n",(0,s.jsx)(n.h2,{id:"3-commonly-used-settings",children:"3. Commonly Used Settings"}),"\n",(0,s.jsxs)(n.p,{children:["We take the content of ",(0,s.jsx)(n.code,{children:"scripts/mTAN/HumanActivity.sh"})," as an example:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:'use_multi_gpu=0\nif [ $use_multi_gpu -eq 0 ]; then\n    launch_command="python"\nelse\n    launch_command="accelerate launch"\nfi\n\n. "$(dirname "$(readlink -f "$0")")/../globals.sh" # Import shared information from scripts/globals.sh\n\ndataset_name=$(basename "$0" .sh) # file name\ndataset_subset_name=""\ndataset_id=$dataset_name\nget_dataset_info "$dataset_name" "$dataset_subset_name" # Get dataset information from scripts/globals.sh\n\nmodel_name="$(basename "$(dirname "$(readlink -f "$0")")")" # folder name\nmodel_id=$model_name\n\nseq_len=3000\nfor pred_len in 300; do\n    $launch_command main.py \\\n        --is_training 1 \\\n        --collate_fn "collate_fn" \\\n        --loss "ModelProvidedLoss" \\\n        --use_multi_gpu $use_multi_gpu \\\n        --dataset_root_path $dataset_root_path \\\n        --model_id $model_id \\\n        --model_name $model_name \\\n        --dataset_name $dataset_name \\\n        --dataset_id $dataset_id \\\n        --features M \\\n        --seq_len $seq_len \\\n        --pred_len $pred_len \\\n        --enc_in $n_variables \\\n        --dec_in $n_variables \\\n        --c_out $n_variables \\\n        --train_epochs 300 \\\n        --patience 10 \\\n        --val_interval 1 \\\n        --itr 5 \\\n        --batch_size 32 \\\n        --learning_rate 1e-3\ndone\n'})}),"\n",(0,s.jsx)(n.p,{children:"These fields are vital:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"use_multi_gpu=0"}),": Change to ",(0,s.jsx)(n.code,{children:"1"})," if you want to enable parallel training via ",(0,s.jsx)(n.a,{href:"https://huggingface.co/docs/accelerate/en/index",children:"accelerate"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:'dataset_name=$(basename "$0" .sh)'}),": Retrieve the file name of current script file, no need to change. After passing to ",(0,s.jsx)(n.code,{children:"--dataset_name"}),", PyOmniTS will automatically find the corresponding dataset class with the exact same file name under ",(0,s.jsx)(n.code,{children:"data/data_provider/datasets/"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"dataset_id"}),": Only affects the folder name for storing experiment results, unlike ",(0,s.jsx)(n.code,{children:"dataset_name"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:'model_name="$(basename "$(dirname "$(readlink -f "$0")")")"'}),": Retrieve the folder name where current script file is placed, no need to change. After passing to ",(0,s.jsx)(n.code,{children:"--model_name"}),", PyOmniTS will automatically find the corresponding model class with the exact same file name under ",(0,s.jsx)(n.code,{children:"models/"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"model_id"}),": Only affects the folder name for storing experiment results, unlike ",(0,s.jsx)(n.code,{children:"model_name"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"seq_len=3000"}),": The lookback window length of input time series."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"for pred_len in 300; do"}),": The forecast window length of forecast targets."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--is_training 1"}),": Change to ",(0,s.jsx)(n.code,{children:"0"})," if you want testing only, instead of training+testing when set to ",(0,s.jsx)(n.code,{children:"1"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:'--collate_fn "collate_fn"'}),": Some datasets and models need special collate_fn for ",(0,s.jsx)(n.code,{children:"torch.utils.data.DataLoader"}),". e.g., In the above example, PyOmniTS will try to load the function with the exact same name in ",(0,s.jsx)(n.code,{children:"data/data_provider/datasets/HumanActivity.py"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:'--loss "ModelProvidedLoss"'}),": Loss function for training. PyOmniTS will automatically find the corresponding loss function class with the exact same file name under ",(0,s.jsx)(n.code,{children:"loss_fns/"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--train_epochs 300"}),": Maximum training epochs. Normally, this is never reached, since early stopping is used."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--patience 10"}),": Early stop patience (counter +1 when validation loss is not decreasing)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--val_interval 1"}),": Frequency (epoch) for calculating validation loss. It should be noted that it will affect early stopping (e.g., ",(0,s.jsx)(n.code,{children:"--val_interval 2"})," and ",(0,s.jsx)(n.code,{children:"--patience 10"})," will wait for 20 epoches before early stopping)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--itr 5"}),": Number of runs (for mean/std calculation of metrics)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--batch_size 32"}),": Batch size."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"--learning_rate 1e-3"})," Learning rate."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"4-other-settings",children:"4. Other Settings"}),"\n",(0,s.jsxs)(n.p,{children:["All settings are available in ",(0,s.jsx)(n.code,{children:"utils/configs.py"})," with detailed comments."]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453(e,n,t){t.d(n,{R:()=>l,x:()=>r});var i=t(6540);const s={},a=i.createContext(s);function l(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);