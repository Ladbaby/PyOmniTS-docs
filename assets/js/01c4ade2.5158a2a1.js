"use strict";(globalThis.webpackChunkpy_omni_ts_docs=globalThis.webpackChunkpy_omni_ts_docs||[]).push([[125],{5813(e){e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"iclr-2026","metadata":{"permalink":"/PyOmniTS-docs/blog/iclr-2026","editUrl":"https://github.com/Ladbaby/PyOmniTS-docs/tree/main/blog/2026-01-26-ICLR2026/index.md","source":"@site/blog/2026-01-26-ICLR2026/index.md","title":"ICLR 2026","description":"Learning Recursive Multi-Scale Representations for Irregular Multivariate Time Series Forecasting","date":"2026-01-26T00:00:00.000Z","tags":[],"readingTime":1.64,"hasTruncateMarker":true,"authors":[{"name":"Boyuan Li","title":"PhD Student","page":{"permalink":"/PyOmniTS-docs/blog/authors/ladbaby"},"socials":{"github":"https://github.com/Ladbaby","scholar":"https://scholar.google.com/citations?user=CWOBJxIAAAAJ&hl=en"},"imageURL":"https://github.com/Ladbaby.png","key":"Ladbaby"}],"frontMatter":{"slug":"iclr-2026","title":"ICLR 2026","authors":["Ladbaby"]},"unlisted":false,"nextItem":{"title":"ICML 2025","permalink":"/PyOmniTS-docs/blog/icml-2025"}},"content":"## Learning Recursive Multi-Scale Representations for Irregular Multivariate Time Series Forecasting\\r\\n\\r\\nBoyuan Li, Zhen Liu, Yicheng Luo, Qianli Ma\u2020\\r\\n\\r\\n![](./model_architecture.png)\\r\\n\\r\\n### Links\\r\\n\\r\\n- **OpenReview**: https://openreview.net/forum?id=JEIDxiTWzB\\r\\n\\r\\n### Citation\\r\\n\\r\\n```\\r\\n@inproceedings{li_LearningRecursiveMultiScale_2026,\\r\\n    author = {Li, Boyuan and Liu, Zhen and Luo, Yicheng  and Ma, Qianli},\\r\\n    booktitle = {International Conference on Learning Representations},\\r\\n    title = {Learning Recursive Multi-Scale Representations for Irregular Multivariate Time Series Forecasting},\\r\\n    year = {2026}\\r\\n}\\r\\n```\\r\\n\\r\\n\x3c!-- truncate --\x3e\\r\\n\\r\\n### Highlights\\r\\n\\r\\n- We introduce **recursive splitting** based on time periods for IMTS samples to **preserve the original sampling patterns** across all scale levels, and leverage IMTS backbones to capture dependencies in different time periods as multi-scale representations.\\r\\n- We propose **ReIMTS**, a recursive multi-scale method for IMTS forecasting. Using irregularity-aware representation fusion, it recursively captures global-to-local dependencies and provides accurate predictions.\\r\\n- Extensive experiments including twenty-six baseline methods and five IMTS datasets on IMTS forecasting are conducted. Tested on six IMTS backbones, ReIMTS consistently boosts their forecasting performance in all settings while maintaining good efficiency.\\r\\n\\r\\n### Abstract\\r\\n\\r\\nIrregular Multivariate Time Series (IMTS) are characterized by uneven intervals between consecutive timestamps, which carry sampling pattern information valuable and informative for learning temporal and variable dependencies.\\r\\nIn addition, IMTS often exhibit diverse dependencies across multiple time scales.\\r\\nHowever, many existing multi-scale IMTS methods use resampling to obtain the coarse series, which can alter the original timestamps and disrupt the sampling pattern information.\\r\\nTo address the challenge, we propose ReIMTS, a **R**cursive multi-scale modeling approach for **I**rregular **M**ultivariate **T**ime **S**eries forecasting.\\r\\nInstead of resampling, ReIMTS keeps timestamps unchanged and recursively splits each sample into subsamples with progressively shorter time periods.\\r\\nBased on the original sampling timestamps in these long-to-short subsamples, an irregularity-aware representation fusion mechanism is proposed to capture global-to-local dependencies for accurate forecasting.\\r\\nExtensive experiments demonstrate an average performance improvement of 29.1\\\\% in the forecasting task across different models and real-world datasets.\\r\\nOur code is available at https://github.com/Ladbaby/PyOmniTS."},{"id":"icml-2025","metadata":{"permalink":"/PyOmniTS-docs/blog/icml-2025","editUrl":"https://github.com/Ladbaby/PyOmniTS-docs/tree/main/blog/2025-05-01-ICML2025/index.md","source":"@site/blog/2025-05-01-ICML2025/index.md","title":"ICML 2025","description":"HyperIMTS: Hypergraph Neural Network for Irregular Multivariate Time Series Forecasting","date":"2025-05-01T00:00:00.000Z","tags":[],"readingTime":1.93,"hasTruncateMarker":true,"authors":[{"name":"Boyuan Li","title":"PhD Student","page":{"permalink":"/PyOmniTS-docs/blog/authors/ladbaby"},"socials":{"github":"https://github.com/Ladbaby","scholar":"https://scholar.google.com/citations?user=CWOBJxIAAAAJ&hl=en"},"imageURL":"https://github.com/Ladbaby.png","key":"Ladbaby"}],"frontMatter":{"slug":"icml-2025","title":"ICML 2025","authors":["Ladbaby"]},"unlisted":false,"prevItem":{"title":"ICLR 2026","permalink":"/PyOmniTS-docs/blog/iclr-2026"}},"content":"## HyperIMTS: Hypergraph Neural Network for Irregular Multivariate Time Series Forecasting \\r\\n\\r\\nBoyuan Li, Yicheng Luo, Zhen Liu, Junhao Zheng, Jianming Lv, Qianli Ma\u2020\\r\\n\\r\\n![](./hypergraph_representation.png)\\r\\n\\r\\n### Links\\r\\n\\r\\n- **poster**: https://icml.cc/virtual/2025/poster/43741\\r\\n- **OpenReview**: https://openreview.net/forum?id=u8wRbX2r2V\\r\\n- **arXiv**: https://arxiv.org/abs/2505.17431\\r\\n\\r\\n### Citation\\r\\n\\r\\n```\\r\\n@inproceedings{li_HyperIMTSHypergraphNeural_2025,\\r\\n    author = {Li, Boyuan and Luo, Yicheng and Liu, Zhen and Zheng, Junhao and Lv, Jianming and Ma, Qianli},\\r\\n    booktitle = {Forty-Second International Conference on Machine Learning},\\r\\n    title = {HyperIMTS: Hypergraph Neural Network for Irregular Multivariate Time Series Forecasting},\\r\\n    year = {2025}\\r\\n}\\r\\n```\\r\\n\\r\\n\x3c!-- truncate --\x3e\\r\\n\\r\\n### Highlights\\r\\n\\r\\n- We propose a new **hypergraph modeling approach** to represent both observed values and their dependencies in IMTS, which **does not require padding** and **remains extensible for dependency learning**.\\r\\n- Based on the hypergraph representation, we propose **HyperIMTS**, a hypergraph neural network for the IMTS forecasting task. It leverages timestamp information preserved in the graph to adaptively capture both time-aware and overall variable dependencies, enabling irregularity-aware learning and accurate forecasting.\\r\\n- We build a unified, extensible, and highly flexible code pipeline for fair IMTS forecasting benchmarking across time series models from various fields and tasks, covering twenty-seven state-of-the-art models and five IMTS datasets. Extensive empirical results demonstrate the low forecast error and high efficiency of HyperIMTS.\\r\\n\\r\\n### Abstract\\r\\n\\r\\nIrregular multivariate time series (IMTS) are characterized by irregular time intervals within variables and unaligned observations across variables, posing challenges in learning temporal and variable dependencies. \\r\\nMany existing IMTS models either require padded samples to learn separately from temporal and variable dimensions, or represent original samples via bipartite graphs or sets.\\r\\nHowever, the former approaches often need to handle extra padding values affecting efficiency and disrupting original sampling patterns, while the latter ones have limitations in capturing dependencies among unaligned observations.\\r\\nTo represent and learn both dependencies from original observations in a unified form, we propose HyperIMTS, a **Hyper**graph neural network for **I**rregular **M**ultivariate **T**ime **S**eries forecasting.\\r\\nObserved values are converted as nodes in the hypergraph, interconnected by temporal and variable hyperedges to enable message passing among all observations.\\r\\nThrough irregularity-aware message passing, HyperIMTS captures variable dependencies in a time-adaptive way to achieve accurate forecasting. \\r\\nExperiments demonstrate HyperIMTS\'s competitive performance among state-of-the-art models in IMTS forecasting with low computational cost.\\r\\nOur code is available at https://github.com/qianlima-lab/PyOmniTS."}]}}')}}]);