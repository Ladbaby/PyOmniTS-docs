"use strict";(globalThis.webpackChunkpy_omni_ts_docs=globalThis.webpackChunkpy_omni_ts_docs||[]).push([[108],{5967(e,n,s){s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"forecasting/API","title":"\ud83e\udde9 API Definition for Forecasting","description":"Models, datasets, and loss functions follow predefined naming rules to be compatible with each other.","source":"@site/docs/forecasting/1_API.md","sourceDirName":"forecasting","slug":"/forecasting/API","permalink":"/PyOmniTS-docs/docs/forecasting/API","draft":false,"unlisted":false,"editUrl":"https://github.com/Ladbaby/PyOmniTS-docs/tree/main/docs/forecasting/1_API.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Forecasting","permalink":"/PyOmniTS-docs/docs/category/forecasting"}}');var r=s(4848),a=s(8453);const l={sidebar_position:1},o="\ud83e\udde9 API Definition for Forecasting",d={},c=[{value:"1. \ud83e\udd16 Model API",id:"1--model-api",level:2},{value:"2. \ud83d\udcbe Dataset API",id:"2--dataset-api",level:2},{value:"3. \ud83d\udcc9 Loss Function API",id:"3--loss-function-api",level:2}];function t(e){const n={blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"-api-definition-for-forecasting",children:"\ud83e\udde9 API Definition for Forecasting"})}),"\n",(0,r.jsx)(n.p,{children:"Models, datasets, and loss functions follow predefined naming rules to be compatible with each other."}),"\n",(0,r.jsxs)(n.p,{children:["e.g., when training model ",(0,r.jsx)(n.strong,{children:"Transformer"})," on dataset ",(0,r.jsx)(n.strong,{children:"Human Activity"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Model: in ",(0,r.jsx)(n.code,{children:"models/Transformer.py"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def forward(\n    self, \n    x: Tensor,\n    x_mark: Tensor | None = None,\n    y: Tensor | None = None,\n    y_mark: Tensor | None = None,\n    y_mask: Tensor | None = None,\n    y_class: Tensor | None = None,\n    **kwargs\n):\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Dataset: in ",(0,r.jsx)(n.code,{children:"collate_fn"})," of ",(0,r.jsx)(n.code,{children:"data/data_provider/datasets/HumanActivity.py"})," (further redirected to ",(0,r.jsx)(n.code,{children:"data/dependencies/tsdm/PyOmniTS/tsdmDataset.py"}),"):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'return {\n    "x": torch.nan_to_num(xs),\n    "x_mark": fix_nan_x_mark(x_marks.unsqueeze(-1), seq_len=configs.seq_len).float(),\n    "x_mask": x_masks.float(),\n    "y": torch.nan_to_num(ys),\n    "y_mark": fix_nan_y_mark(y_marks.unsqueeze(-1)).float(),\n    "y_mask": y_masks.float(),\n    "sample_ID": sample_IDs\n}\n'})}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:["Tips: ",(0,r.jsx)(n.code,{children:"collate_fn"})," will be called after the ",(0,r.jsx)(n.code,{children:"__getitem__"})," function of dataset, processing each batch separately."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Comparing the input arguments of the model's ",(0,r.jsx)(n.code,{children:"forward"})," and the keys in return value of the dataset, they have ",(0,r.jsx)(n.strong,{children:"common"})," parts (",(0,r.jsx)(n.code,{children:"x"}),", ",(0,r.jsx)(n.code,{children:"x_mark"}),", ",(0,r.jsx)(n.code,{children:"y"}),", ",(0,r.jsx)(n.code,{children:"y_mark"}),", ",(0,r.jsx)(n.code,{children:"y_mask"}),") and ",(0,r.jsx)(n.strong,{children:"different"})," ones (",(0,r.jsx)(n.code,{children:"y_class"})," in model; ",(0,r.jsx)(n.code,{children:"x_mask"}),", ",(0,r.jsx)(n.code,{children:"sample_ID"})," in dataset)."]}),"\n",(0,r.jsxs)(n.p,{children:["During training, data with same names will be passed to corresponding arguments in model (",(0,r.jsx)(n.code,{children:"x"}),", ",(0,r.jsx)(n.code,{children:"x_mark"}),", ",(0,r.jsx)(n.code,{children:"y"}),", ",(0,r.jsx)(n.code,{children:"y_mark"}),", ",(0,r.jsx)(n.code,{children:"y_mask"}),"), while unknown names (",(0,r.jsx)(n.code,{children:"x_mask"}),", ",(0,r.jsx)(n.code,{children:"sample_ID"}),") from the dataset will be ",(0,r.jsxs)(n.strong,{children:["ignored and held by ",(0,r.jsx)(n.code,{children:"**kwargs"})]}),", which is never accessed."]}),"\n",(0,r.jsxs)(n.p,{children:["As for the argument not provided by forecasting dataset Human Activity (",(0,r.jsx)(n.code,{children:"y_class"}),", the class label for classification task), they will be ",(0,r.jsx)(n.strong,{children:"set to default values"})," in subsequent initialization in model's ",(0,r.jsx)(n.code,{children:"forward"})," function:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# BEGIN adaptor\n...\nif y_class is None:\n    if self.configs.task_name == "classification":\n        logger.warning(f"y_class is missing for the model input. This is only reasonable when the model is testing flops!")\n    y_class = torch.ones((BATCH_SIZE), dtype=x.dtype, device=x.device)\n...\n# END adaptor\n'})}),"\n",(0,r.jsx)(n.p,{children:"Thereby, any model can train on any dataset without raising errors."}),"\n",(0,r.jsx)(n.h2,{id:"1--model-api",children:"1. \ud83e\udd16 Model API"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Python file name"}),"\n",(0,r.jsxs)(n.p,{children:["Adapter model class should be placed in a file under ",(0,r.jsx)(n.code,{children:"models/${YOUR_MODEL_NAME}.py"}),", where ",(0,r.jsx)(n.code,{children:"${YOUR_MODEL_NAME}"})," is to be provided in the ",(0,r.jsx)(n.code,{children:"--model_name"})," argument helping the pipeline import the model class automatically."]}),"\n",(0,r.jsxs)(n.p,{children:["Other model dependencies are encouraged to be put under ",(0,r.jsx)(n.code,{children:"models/layers/${YOUR_MODEL_NAME}/"})," folder"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Adapter class name"}),"\n",(0,r.jsxs)(n.p,{children:["The outer model class should be renamed as ",(0,r.jsx)(n.code,{children:"Model"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class Model(nn.Module):\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.code,{children:"__init__()"})}),"\n",(0,r.jsx)(n.p,{children:"Minimal example:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def __init__(\n    self,\n    configs: ExpConfigs\n):\n    super().__init__()\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Existing arguments can be found in ",(0,r.jsx)(n.code,{children:"utils/configs.py"}),", and ",(0,r.jsx)(n.code,{children:"utils/ExpConfigs.py"})," is used to support pylint checking."]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:["\u2757\ufe0fThe best practice is to treat global configuration as ",(0,r.jsx)(n.strong,{children:"read only"}),"."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"forward()"})," input arguments"]}),"\n",(0,r.jsx)(n.p,{children:"Minimal example:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def forward(\n    self, \n    x: Tensor, # mandatory; lookback sequence; (batch_size, seq_len, enc_in)\n    y: Tensor | None = None, # mandatory; forecast groundtruth; (batch_size, pred_len, c_out)\n    **kwargs # mandatory; container for redundant input parameters\n):\n"})}),"\n",(0,r.jsx)(n.p,{children:"Other available args:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'x_mark: Tensor | None = None, # lookback timestamps; (batch_size, seq_len, enc_in)\nx_mask: Tensor | None = None, # lookback mask; (batch_size, seq_len, enc_in)\ny_mark: Tensor | None = None, # forecast timestamps; (batch_size, pred_len, c_out)\ny_mask: Tensor | None = None, # forecast mask; (batch_size, pred_len, c_out)\nexp_stage: str = "train", # possible values: ["train", "val", "test"]\ntrain_stage: int = 1, # Only available during train or val. See --n_train_stages in utils/configs.py for explanations.\ncurrent_epoch: int = 0, # Only available during train or val. Current training epoch.\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"forward()"})," return value"]}),"\n",(0,r.jsx)(n.p,{children:"Minimal example:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'return {\n    "pred": ..., # model\'s output, should be of same shape as "true"\n    "true": ..., # groundtruth. Normally it is "y"\n}\n'})}),"\n",(0,r.jsx)(n.p,{children:"Other available items:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'"mask": ..., # mask for groundtruth. Normally it is "y_mask"\n"loss": ..., # commonly used with --loss "ModelProvidedLoss"\n'})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"2--dataset-api",children:"2. \ud83d\udcbe Dataset API"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Python file name"}),"\n",(0,r.jsxs)(n.p,{children:["Adapter dataset class should be placed in a file under ",(0,r.jsx)(n.code,{children:"data/data_provider/datasets/${YOUR_DATASET_NAME}.py"}),", where ",(0,r.jsx)(n.code,{children:"${YOUR_DATASET_NAME}"})," is to be provided in the ",(0,r.jsx)(n.code,{children:"--dataset_name"})," argument helping the pipeline import the dataset class automatically."]}),"\n",(0,r.jsxs)(n.p,{children:["Other model dependencies are encouraged to be put under ",(0,r.jsx)(n.code,{children:"data/dependencies/${YOUR_DATASET_NAME}/"})," folder"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Adapter class name"}),"\n",(0,r.jsxs)(n.p,{children:["The outer dataset class should be renamed as ",(0,r.jsx)(n.code,{children:"Data"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class Data(Dataset):\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.code,{children:"__init__()"})}),"\n",(0,r.jsx)(n.p,{children:"Minimal example:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def __init__(\n    self, \n    configs: ExpConfigs,\n    flag: str = \'train\' # Possible values: ["train", "val", "test", "test_all"]\n):\n'})}),"\n",(0,r.jsxs)(n.p,{children:["Existing arguments can be found in ",(0,r.jsx)(n.code,{children:"utils/configs.py"}),", and ",(0,r.jsx)(n.code,{children:"utils/ExpConfigs.py"})," is used to support pylint checking."]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:["\u2757\ufe0fThe best practice is to treat global configuration as ",(0,r.jsx)(n.strong,{children:"read only"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"__getitem__()"})," return value"]}),"\n",(0,r.jsx)(n.p,{children:"Minimal example:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'return {\n    "x": ..., # mandatory; lookback sequence; (seq_len, enc_in)\n    "y": ..., # mandatory; forecast groundtruth; (pred_len, c_out)\n}\n'})}),"\n",(0,r.jsx)(n.p,{children:"Other available items:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'"x_mark": ..., # lookback timestamps; (seq_len, enc_in)\n"x_mask": ..., # lookback mask; (seq_len, enc_in)\n"y_mark": ..., # forecast timestamps; (pred_len, c_out)\n"y_mask": ..., # forecast mask; (pred_len, c_out)\n"sample_ID": ..., # sample ID; (1)\n'})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"3--loss-function-api",children:"3. \ud83d\udcc9 Loss Function API"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Python file name"}),"\n",(0,r.jsxs)(n.p,{children:["Loss function class should be placed in a file under ",(0,r.jsx)(n.code,{children:"loss_fns/${YOUR_LOSS_FN}.py"}),", where ",(0,r.jsx)(n.code,{children:"${YOUR_LOSS_FN}"})," is to be provided in the ",(0,r.jsx)(n.code,{children:"--loss"})," argument helping the pipeline import the loss function class automatically."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Adapter class name"}),"\n",(0,r.jsxs)(n.p,{children:["The loss function class should be renamed as ",(0,r.jsx)(n.code,{children:"Loss"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"class Loss(nn.Module):\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.code,{children:"__init__()"})}),"\n",(0,r.jsx)(n.p,{children:"Minimal example:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def __init__(\n    self, \n    configs: ExpConfigs\n):\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Existing arguments can be found in ",(0,r.jsx)(n.code,{children:"utils/args.py"}),", and ",(0,r.jsx)(n.code,{children:"utils/ExpConfigs.py"})," is used to support pylint checking."]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:["\u2757\ufe0fThe best practice is to treat global configuration as ",(0,r.jsx)(n.strong,{children:"read only"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"forward()"})," input arguments"]}),"\n",(0,r.jsx)(n.p,{children:"Minimal example:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"def forward(\n    self, \n    **kwargs # mandatory; container for redundant input parameters\n):\n"})}),"\n",(0,r.jsx)(n.p,{children:"Other available args:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'pred, # model\'s output, should be of same shape as "true"\ntrue, # groundtruth. Normally it is "y"\nmask, # mask for groundtruth. Normally it is "y_mask"\nloss, # commonly used with "ModelProvidedLoss"\n'})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"forward()"})," return value"]}),"\n",(0,r.jsx)(n.p,{children:"Minimal example:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'return {\n    "loss": ..., # of shape (1)\n}\n'})}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(t,{...e})}):t(e)}},8453(e,n,s){s.d(n,{R:()=>l,x:()=>o});var i=s(6540);const r={},a=i.createContext(r);function l(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);